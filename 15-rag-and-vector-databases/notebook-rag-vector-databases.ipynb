{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG) and Vector Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting getenv\n",
      "  Downloading getenv-0.2.0-py3-none-any.whl (2.6 kB)\n",
      "Collecting openai==1.12.0\n",
      "  Using cached openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.12.0) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.12.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.12.0) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.12.0) (2.6.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.12.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.12.0) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.12.0) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.12.0) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.12.0) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.12.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.12.0) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai==1.12.0) (0.4.6)\n",
      "Installing collected packages: getenv, openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.14.2\n",
      "    Uninstalling openai-1.14.2:\n",
      "      Successfully uninstalled openai-1.14.2\n",
      "Successfully installed getenv-0.2.0 openai-1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install getenv openai==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Knowledge base\n",
    "\n",
    "Creating a Azure Cosmos DB database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cosmos\n",
      "  Downloading azure_cosmos-4.6.0-py3-none-any.whl (243 kB)\n",
      "                                              0.0/243.1 kB ? eta -:--:--\n",
      "     -----------------                      112.6/243.1 kB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------------   235.5/243.1 kB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 243.1/243.1 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting azure-core>=1.25.1 (from azure-cosmos)\n",
      "  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
      "                                              0.0/193.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 193.4/193.4 kB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-cosmos) (4.10.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core>=1.25.1->azure-cosmos) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core>=1.25.1->azure-cosmos) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure-cosmos) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure-cosmos) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure-cosmos) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ankshah0\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure-cosmos) (2024.2.2)\n",
      "Installing collected packages: azure-core, azure-cosmos\n",
      "Successfully installed azure-core-1.30.1 azure-cosmos-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create your cosmoss db on Azure CLI using the following commands\n",
    "## az login\n",
    "## az group create -n <resource-group-name> -l <location>\n",
    "## az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>\n",
    "## az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>\n",
    "\n",
    "## Once done navigate to data explorer and create a new database and a new container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import CosmosClient\n",
    "\n",
    "load_dotenv(r\"C:\\Users\\ankshah0\\Documents\\Sapient Documents\\GenAI\\generative-ai-for-beginners\\.env\")\n",
    "\n",
    "# Initialize Cosmos Client\n",
    "url = os.getenv('COSMOS_DB_ENDPOINT')\n",
    "key = os.getenv('COSMOS_DB_KEY')\n",
    "\n",
    "client = CosmosClient(url, credential=key)\n",
    "\n",
    "# Select database\n",
    "database_name = 'rag-cosmos-db'\n",
    "database = client.get_database_client(database_name)\n",
    "\n",
    "# Select container\n",
    "container_name = 'data'\n",
    "container = database.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoint=os.getenv('AZURE_OPENAI_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/own_framework.md</td>\n",
       "      <td># Introduction to Neural Networks. Multi-Layer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/perceptron.md</td>\n",
       "      <td># Introduction to Neural Networks: Perceptron\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path                                               text\n",
       "0     data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...\n",
       "1  data/own_framework.md  # Introduction to Neural Networks. Multi-Layer...\n",
       "2     data/perceptron.md  # Introduction to Neural Networks: Perceptron\\..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame(columns=['path', 'text'])\n",
    "\n",
    "# splitting our data into chunks\n",
    "#data_paths= [\"data/frameworks.md?WT.mc_id=academic-105485-koreyst\", \"data/own_framework.md?WT.mc_id=academic-105485-koreyst\", \"data/perceptron.md?WT.mc_id=academic-105485-koreyst\"]\n",
    "data_paths= [\"data/frameworks.md\", \"data/own_framework.md\", \"data/perceptron.md\"]\n",
    "\n",
    "for path in data_paths:\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    # Append the file path and text to the DataFrame\n",
    "    new_row = pd.DataFrame([{'path': path, 'text': file_content}])\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>[# Neural Network Frameworks As we have learne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/own_framework.md</td>\n",
       "      <td># Introduction to Neural Networks. Multi-Layer...</td>\n",
       "      <td>[# Introduction to Neural Networks. Multi-Laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/perceptron.md</td>\n",
       "      <td># Introduction to Neural Networks: Perceptron\\...</td>\n",
       "      <td>[# Introduction to Neural Networks: Perceptron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path                                               text  \\\n",
       "0     data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "1  data/own_framework.md  # Introduction to Neural Networks. Multi-Layer...   \n",
       "2     data/perceptron.md  # Introduction to Neural Networks: Perceptron\\...   \n",
       "\n",
       "                                              chunks  \n",
       "0  [# Neural Network Frameworks As we have learne...  \n",
       "1  [# Introduction to Neural Networks. Multi-Laye...  \n",
       "2  [# Introduction to Neural Networks: Perceptron...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_text(text, max_length, min_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "\n",
    "    # If the last chunk didn't reach the minimum length, add it anyway\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Assuming analyzed_df is a pandas DataFrame and 'output_content' is a column in that DataFrame\n",
    "splitted_df = df.copy()\n",
    "splitted_df['chunks'] = splitted_df['text'].apply(lambda x: split_text(x, 400, 300))\n",
    "\n",
    "splitted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \n",
       "0  # Neural Network Frameworks As we have learned...  \n",
       "0  descent optimization While the `numpy` library...  \n",
       "0  should give us the opportunity to compute grad...  \n",
       "0  those computations on GPUs is very important. ...  \n",
       "0  API, there is also higher-level API, called Ke...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'chunks' is a column of lists in the DataFrame splitted_df, we will split the chunks into different rows\n",
    "flattened_df = splitted_df.explode('chunks')\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting our text to embeddings\n",
    "\n",
    "Converting out text  to embeddings, and storing them in our database in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\") \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_version = \"2023-07-01-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"my-text-embedding-ada-002\"):\n",
    "    # Create embeddings for each document chunk\n",
    "    embeddings = openai.embeddings.create(input = text, model=model).data[0].embedding\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.017071647569537163,\n",
       " 0.002827746095135808,\n",
       " 0.025336062535643578,\n",
       " -0.038865819573402405,\n",
       " 0.006856478750705719,\n",
       " 0.003945613279938698,\n",
       " -0.006249200087040663,\n",
       " -0.0032145045697689056,\n",
       " -0.0029091688338667154,\n",
       " -0.029339350759983063,\n",
       " 0.03490324318408966,\n",
       " 0.020450694486498833,\n",
       " 0.001463914173655212,\n",
       " 0.0030346957501024008,\n",
       " -0.01465610507875681,\n",
       " -0.011019219644367695,\n",
       " 0.02207915112376213,\n",
       " 0.009105783887207508,\n",
       " -0.029339350759983063,\n",
       " -0.020572828128933907,\n",
       " -0.03555462509393692,\n",
       " -0.003704737639054656,\n",
       " 0.01300729252398014,\n",
       " -0.03441470488905907,\n",
       " -0.03042498789727688,\n",
       " -0.0015835039084777236,\n",
       " 0.01544319186359644,\n",
       " -0.043642621487379074,\n",
       " -0.007538394536823034,\n",
       " -0.014235420152544975,\n",
       " 0.01971788890659809,\n",
       " 0.012606964446604252,\n",
       " -0.012668031267821789,\n",
       " -0.015592467039823532,\n",
       " -0.004719130229204893,\n",
       " 0.011114212684333324,\n",
       " 0.001191656687296927,\n",
       " 0.008203347213566303,\n",
       " -0.00034668302396312356,\n",
       " -0.0017929980531334877,\n",
       " 0.04033143073320389,\n",
       " 0.011290628463029861,\n",
       " -0.00979109201580286,\n",
       " -0.007646958343684673,\n",
       " -0.004993931856006384,\n",
       " 0.010707098990678787,\n",
       " -0.025336062535643578,\n",
       " -0.033356208354234695,\n",
       " -0.006300089415162802,\n",
       " 0.0039286501705646515,\n",
       " 0.013041218742728233,\n",
       " 0.023911163210868835,\n",
       " -0.044049736112356186,\n",
       " -0.03297623619437218,\n",
       " -0.021197069436311722,\n",
       " 0.012165923602879047,\n",
       " -0.02629956603050232,\n",
       " 0.012837662361562252,\n",
       " 0.024562545120716095,\n",
       " -0.025906022638082504,\n",
       " 0.002439291449263692,\n",
       " 0.01990787498652935,\n",
       " -0.021305633708834648,\n",
       " 0.0030262141954153776,\n",
       " -0.007307696621865034,\n",
       " -0.019650036469101906,\n",
       " -0.0014537363313138485,\n",
       " 0.02578388713300228,\n",
       " 0.003480824874714017,\n",
       " -0.01648811809718609,\n",
       " 0.0035859961062669754,\n",
       " 0.013251561671495438,\n",
       " -0.025566760450601578,\n",
       " 0.00012626896204892546,\n",
       " 0.015239634551107883,\n",
       " 0.004240770824253559,\n",
       " -0.013665460981428623,\n",
       " 0.001731082797050476,\n",
       " -0.01629813201725483,\n",
       " 0.0025936556048691273,\n",
       " 0.0028955985326319933,\n",
       " -0.030479269102215767,\n",
       " -0.013638319447636604,\n",
       " 0.0013545022811740637,\n",
       " 0.0003615257446654141,\n",
       " -0.004142384976148605,\n",
       " 0.01222020573914051,\n",
       " 0.010008219629526138,\n",
       " 0.008529039099812508,\n",
       " -0.0051296367309987545,\n",
       " 0.04402259737253189,\n",
       " -0.001714967773295939,\n",
       " 0.025118935853242874,\n",
       " 0.008814018219709396,\n",
       " 0.007056643255054951,\n",
       " 0.010774951428174973,\n",
       " -0.01277659460902214,\n",
       " 0.006235629785805941,\n",
       " -0.004386653658002615,\n",
       " -0.009947152808308601,\n",
       " -0.01254589669406414,\n",
       " 0.01810300350189209,\n",
       " -0.014723957516252995,\n",
       " -0.01875438541173935,\n",
       " -0.022241996601223946,\n",
       " 0.0005890430766157806,\n",
       " 0.003996502608060837,\n",
       " 0.0006246655830182135,\n",
       " 0.010354266501963139,\n",
       " -0.0011042967671528459,\n",
       " 0.019052935764193535,\n",
       " 0.022662680596113205,\n",
       " -0.009967508725821972,\n",
       " -0.02444041147828102,\n",
       " -0.012444118969142437,\n",
       " -0.010015005245804787,\n",
       " 0.04130850359797478,\n",
       " -0.008440830744802952,\n",
       " -0.008013361133635044,\n",
       " -0.016230279579758644,\n",
       " 0.012464473955333233,\n",
       " 0.02420971356332302,\n",
       " 0.03712879866361618,\n",
       " -0.006520609371364117,\n",
       " 0.017533043399453163,\n",
       " -0.0012476348783820868,\n",
       " 0.027208786457777023,\n",
       " 0.001680193468928337,\n",
       " -0.01815728470683098,\n",
       " -0.024942519143223763,\n",
       " -0.011935225687921047,\n",
       " 0.008698669262230396,\n",
       " 0.0028599759098142385,\n",
       " 0.021319204941391945,\n",
       " -0.015524614602327347,\n",
       " 0.004152562934905291,\n",
       " 0.015239634551107883,\n",
       " 0.010476401075720787,\n",
       " -0.031130652874708176,\n",
       " 0.005401046015322208,\n",
       " 0.011514541693031788,\n",
       " 0.007484112866222858,\n",
       " -0.02722235769033432,\n",
       " -0.013142997398972511,\n",
       " -0.014954655431210995,\n",
       " 0.0370473749935627,\n",
       " 0.030533552169799805,\n",
       " 0.027235927060246468,\n",
       " 0.013855447061359882,\n",
       " -0.009967508725821972,\n",
       " -0.008386548608541489,\n",
       " -0.010849588550627232,\n",
       " -0.013814736157655716,\n",
       " -0.020247137174010277,\n",
       " 0.006730951834470034,\n",
       " 0.0002890085452236235,\n",
       " -0.004362905398011208,\n",
       " 0.03384474664926529,\n",
       " -0.01166381686925888,\n",
       " 0.014941084198653698,\n",
       " 0.01750590279698372,\n",
       " 0.012885158881545067,\n",
       " -0.017153071239590645,\n",
       " -0.002547855256125331,\n",
       " 0.01597243919968605,\n",
       " 0.012321984395384789,\n",
       " 0.04554248973727226,\n",
       " -0.0017692496767267585,\n",
       " 0.024386130273342133,\n",
       " -0.0015164996730163693,\n",
       " 0.013889373280107975,\n",
       " -0.0017251456156373024,\n",
       " -0.005557106342166662,\n",
       " 0.01380116492509842,\n",
       " 0.020667821168899536,\n",
       " 0.007470542099326849,\n",
       " 0.027439484372735023,\n",
       " 0.005563891492784023,\n",
       " -0.034468986093997955,\n",
       " -0.014710386283695698,\n",
       " 0.01796729862689972,\n",
       " 0.01860511116683483,\n",
       " 0.03050640970468521,\n",
       " 0.011690957471728325,\n",
       " -0.0007786055793985724,\n",
       " -0.013014078140258789,\n",
       " 0.02378902956843376,\n",
       " -0.009743595495820045,\n",
       " 0.004485039506107569,\n",
       " -0.03281338885426521,\n",
       " -0.01129741407930851,\n",
       " 0.004922687076032162,\n",
       " -0.002790427301079035,\n",
       " 0.006076176650822163,\n",
       " -0.6261956691741943,\n",
       " -0.0018387982854619622,\n",
       " 0.0370473749935627,\n",
       " -0.03392616659402847,\n",
       " -0.0059099383652210236,\n",
       " -0.01347547397017479,\n",
       " -0.013176923617720604,\n",
       " 0.005767448805272579,\n",
       " -0.008929367177188396,\n",
       " 0.03509322926402092,\n",
       " -0.002690345048904419,\n",
       " 0.01243054773658514,\n",
       " 0.0006479898001998663,\n",
       " -0.016922373324632645,\n",
       " 0.009892870672047138,\n",
       " -0.022621968761086464,\n",
       " 0.009268629364669323,\n",
       " -0.033953309059143066,\n",
       " -0.015619607642292976,\n",
       " 0.000789631565567106,\n",
       " -0.0085629653185606,\n",
       " 0.02361261285841465,\n",
       " -0.021007083356380463,\n",
       " 0.020681392401456833,\n",
       " 0.0023850095458328724,\n",
       " 0.013394051231443882,\n",
       " -0.003058444010093808,\n",
       " 0.0039184726774692535,\n",
       " 0.023734746500849724,\n",
       " 0.029203645884990692,\n",
       " -0.014411835931241512,\n",
       " 0.005781019106507301,\n",
       " 0.014425407163798809,\n",
       " 0.00011927168816328049,\n",
       " 0.04052141681313515,\n",
       " -0.008922582492232323,\n",
       " -0.019039366394281387,\n",
       " 0.03778018057346344,\n",
       " 0.009614676237106323,\n",
       " 0.03501180559396744,\n",
       " -0.03009929694235325,\n",
       " -0.014004722237586975,\n",
       " 0.02541748620569706,\n",
       " 0.011310984380543232,\n",
       " -0.009763951413333416,\n",
       " 0.030017873272299767,\n",
       " 0.011840232647955418,\n",
       " 0.0047937678173184395,\n",
       " 0.004756448790431023,\n",
       " -0.013068360276520252,\n",
       " 0.009044716134667397,\n",
       " 0.00029918638756498694,\n",
       " 0.012586608529090881,\n",
       " 0.023504048585891724,\n",
       " 0.004386653658002615,\n",
       " -0.002318853512406349,\n",
       " 0.006849693600088358,\n",
       " -0.02245912328362465,\n",
       " 0.006897190120071173,\n",
       " 0.006018502172082663,\n",
       " 0.010768165811896324,\n",
       " -0.008630816824734211,\n",
       " -0.04945078119635582,\n",
       " -0.01340083684772253,\n",
       " -0.01889009028673172,\n",
       " 0.007009146269410849,\n",
       " -0.021916305646300316,\n",
       " 0.02925792708992958,\n",
       " -0.02278481423854828,\n",
       " -0.010903870686888695,\n",
       " 0.01962289586663246,\n",
       " 0.024874666705727577,\n",
       " 0.019568614661693573,\n",
       " 0.0065070390701293945,\n",
       " 0.007287341170012951,\n",
       " 0.022011298686265945,\n",
       " 0.016460977494716644,\n",
       " -0.0032246822956949472,\n",
       " 0.0022628754377365112,\n",
       " 0.011141353286802769,\n",
       " 0.002554640406742692,\n",
       " 0.003898116759955883,\n",
       " -0.01893080212175846,\n",
       " -0.014221849851310253,\n",
       " 0.005998146720230579,\n",
       " 0.008454401046037674,\n",
       " -0.01652882993221283,\n",
       " -0.007918368093669415,\n",
       " 0.007633388042449951,\n",
       " -1.0913358892139513e-05,\n",
       " 0.007395904511213303,\n",
       " 0.02268982119858265,\n",
       " -0.017248064279556274,\n",
       " -0.06969792395830154,\n",
       " -0.00040562974754720926,\n",
       " 0.010612105019390583,\n",
       " 0.007735166233032942,\n",
       " 0.013224420137703419,\n",
       " 0.01787230558693409,\n",
       " -0.012946225702762604,\n",
       " -0.008847944438457489,\n",
       " -0.006025287322700024,\n",
       " 0.02129206247627735,\n",
       " -0.003969361539930105,\n",
       " -0.010564608499407768,\n",
       " 0.016786668449640274,\n",
       " -0.014357554726302624,\n",
       " 0.04714380204677582,\n",
       " 0.03218914940953255,\n",
       " -0.02570246532559395,\n",
       " -0.03156490623950958,\n",
       " -0.027928022667765617,\n",
       " -0.01062567625194788,\n",
       " 0.022621968761086464,\n",
       " 6.76933050272055e-05,\n",
       " -0.03102208860218525,\n",
       " -0.008155850693583488,\n",
       " 0.0082169184461236,\n",
       " -0.008121924474835396,\n",
       " -0.01921578124165535,\n",
       " 0.009065072052180767,\n",
       " 0.013543326407670975,\n",
       " -0.006846300791949034,\n",
       " -0.0005546928732655942,\n",
       " 0.01815728470683098,\n",
       " 0.0062220594845712185,\n",
       " -0.030940664932131767,\n",
       " -0.018211567774415016,\n",
       " -0.02699165977537632,\n",
       " -0.012260917574167252,\n",
       " -0.003718307940289378,\n",
       " -0.022798385471105576,\n",
       " 0.0008019297965802252,\n",
       " -0.018021579831838608,\n",
       " 0.026150289922952652,\n",
       " 0.010646031238138676,\n",
       " 0.017465190961956978,\n",
       " -0.02148205041885376,\n",
       " 0.0011322859209030867,\n",
       " -0.03362761810421944,\n",
       " -0.0016199745004996657,\n",
       " -0.021183500066399574,\n",
       " 0.024562545120716095,\n",
       " -0.021495619788765907,\n",
       " -0.01488680299371481,\n",
       " 0.005536750890314579,\n",
       " -0.01800801046192646,\n",
       " -0.005665670149028301,\n",
       " 0.008725810796022415,\n",
       " 0.00380312348715961,\n",
       " 0.0012145568616688251,\n",
       " 0.010361052118241787,\n",
       " 2.0117156964261085e-05,\n",
       " 0.0038540128152817488,\n",
       " 0.01648811809718609,\n",
       " -0.019921446219086647,\n",
       " -0.01773660071194172,\n",
       " -0.034333281219005585,\n",
       " -0.004644492641091347,\n",
       " -0.03346477076411247,\n",
       " -0.027615901082754135,\n",
       " 0.028742250055074692,\n",
       " -0.028959376737475395,\n",
       " 0.017994439229369164,\n",
       " -0.025661753490567207,\n",
       " -0.028307994827628136,\n",
       " -0.019568614661693573,\n",
       " 0.004637707024812698,\n",
       " 0.004814123269170523,\n",
       " -0.024291137233376503,\n",
       " -0.01317013893276453,\n",
       " -0.039055805653333664,\n",
       " -0.0010729150380939245,\n",
       " 0.014751098118722439,\n",
       " 0.010218561626970768,\n",
       " 0.0064561497420072556,\n",
       " -0.011120998300611973,\n",
       " -0.016230279579758644,\n",
       " 0.016963083297014236,\n",
       " -0.018455835059285164,\n",
       " 0.007355193141847849,\n",
       " -0.016026722267270088,\n",
       " -0.025675324723124504,\n",
       " -0.009892870672047138,\n",
       " 0.0365859791636467,\n",
       " -0.006527394987642765,\n",
       " 0.009981079027056694,\n",
       " 0.0013646801235154271,\n",
       " -0.04635671526193619,\n",
       " -0.013461903668940067,\n",
       " -0.005540143232792616,\n",
       " 0.02463039755821228,\n",
       " -0.028715109452605247,\n",
       " 0.010198206640779972,\n",
       " -0.012213421054184437,\n",
       " 0.0003163615183439106,\n",
       " -0.0025817814748734236,\n",
       " 0.019650036469101906,\n",
       " -0.02190273441374302,\n",
       " 0.0067750560119748116,\n",
       " 0.0027598938904702663,\n",
       " -0.015131071209907532,\n",
       " 0.012498400174081326,\n",
       " -0.01990787498652935,\n",
       " 0.012851232662796974,\n",
       " 0.002749715931713581,\n",
       " 0.01963646709918976,\n",
       " -0.026285994797945023,\n",
       " -0.01633884198963642,\n",
       " 0.002848101779818535,\n",
       " 0.006337408442050219,\n",
       " -0.016325272619724274,\n",
       " -0.009872514754533768,\n",
       " -0.013597608543932438,\n",
       " -0.01760089583694935,\n",
       " 0.03199916332960129,\n",
       " 0.021007083356380463,\n",
       " 0.006982005666941404,\n",
       " -0.007830159738659859,\n",
       " -0.006764878053218126,\n",
       " -0.01256625261157751,\n",
       " -0.004892153665423393,\n",
       " 0.02495609037578106,\n",
       " -0.0047937678173184395,\n",
       " -0.0030058585107326508,\n",
       " 0.021047795191407204,\n",
       " -0.015904588624835014,\n",
       " 0.00909899827092886,\n",
       " -0.011636675335466862,\n",
       " -0.04852798953652382,\n",
       " -0.0016539007192477584,\n",
       " 0.018170855939388275,\n",
       " -0.002203504554927349,\n",
       " 0.014248990453779697,\n",
       " 0.028497980907559395,\n",
       " 0.0028447092045098543,\n",
       " 0.0034689507447183132,\n",
       " 0.0017107269959524274,\n",
       " 0.06421545147895813,\n",
       " -0.0035554624628275633,\n",
       " -0.00039545190520584583,\n",
       " 0.00935005210340023,\n",
       " 0.01000143401324749,\n",
       " -0.013563682325184345,\n",
       " 0.01842869445681572,\n",
       " 0.013584038242697716,\n",
       " 0.0476866215467453,\n",
       " 0.014710386283695698,\n",
       " -0.018170855939388275,\n",
       " -0.012247346341609955,\n",
       " -0.009736809879541397,\n",
       " 0.002671685768291354,\n",
       " -0.004149170592427254,\n",
       " 0.013522970490157604,\n",
       " 0.00724662933498621,\n",
       " -0.015158211812376976,\n",
       " 0.009112568572163582,\n",
       " 0.01768231950700283,\n",
       " 0.015904588624835014,\n",
       " 0.02513250522315502,\n",
       " 0.017424480989575386,\n",
       " 0.00634419359266758,\n",
       " 0.0019999477081000805,\n",
       " -0.024426842108368874,\n",
       " -0.0035622476134449244,\n",
       " -0.0063984752632677555,\n",
       " 0.01374688372015953,\n",
       " -0.014371125027537346,\n",
       " -0.016040291637182236,\n",
       " -0.0034570766147226095,\n",
       " -0.01336012501269579,\n",
       " -0.020206425338983536,\n",
       " 0.012681601569056511,\n",
       " -0.0180487222969532,\n",
       " -0.00028370757354423404,\n",
       " 0.014289702288806438,\n",
       " -0.0034842174500226974,\n",
       " 0.007830159738659859,\n",
       " -0.004675026051700115,\n",
       " 0.015945298597216606,\n",
       " -0.01120242103934288,\n",
       " -0.009451830759644508,\n",
       " 0.013299058191478252,\n",
       " 0.018184427171945572,\n",
       " 0.004949828144162893,\n",
       " -0.01416756771504879,\n",
       " -0.008115139789879322,\n",
       " 0.004563069436699152,\n",
       " 0.0040881033055484295,\n",
       " -0.006849693600088358,\n",
       " 0.006703810766339302,\n",
       " -0.005991361569613218,\n",
       " -0.011324554681777954,\n",
       " -0.008271199651062489,\n",
       " 0.002748019527643919,\n",
       " -0.0005161018343642354,\n",
       " 0.029665041714906693,\n",
       " -0.010157494805753231,\n",
       " 0.008590105921030045,\n",
       " -0.027520908042788506,\n",
       " 0.03403473272919655,\n",
       " 0.01074102520942688,\n",
       " -0.011195635423064232,\n",
       " -0.014981796033680439,\n",
       " 0.036830250173807144,\n",
       " 0.011263487860560417,\n",
       " -0.02357190102338791,\n",
       " -0.01004893146455288,\n",
       " 0.022513404488563538,\n",
       " -0.027005229145288467,\n",
       " 0.008814018219709396,\n",
       " -0.00793872307986021,\n",
       " 0.012369480915367603,\n",
       " 0.005156777799129486,\n",
       " 0.018170855939388275,\n",
       " -0.011005649343132973,\n",
       " 0.009913226589560509,\n",
       " 0.005448542535305023,\n",
       " 0.008461186662316322,\n",
       " 0.01462896354496479,\n",
       " 0.011948796920478344,\n",
       " -0.013787594623863697,\n",
       " -0.016515258699655533,\n",
       " 0.019283633679151535,\n",
       " 0.03213486820459366,\n",
       " 0.025159645825624466,\n",
       " -0.020206425338983536,\n",
       " 0.01620313711464405,\n",
       " -0.021862022578716278,\n",
       " -0.011935225687921047,\n",
       " -0.01777731254696846,\n",
       " -0.025118935853242874,\n",
       " 0.018320130184292793,\n",
       " -0.009668958373367786,\n",
       " 0.00979109201580286,\n",
       " 0.009635032154619694,\n",
       " 0.015063218772411346,\n",
       " -0.02587888203561306,\n",
       " 0.01737019792199135,\n",
       " 0.02912222221493721,\n",
       " -0.007646958343684673,\n",
       " -0.0015818076208233833,\n",
       " 0.004596995655447245,\n",
       " -0.002576692495495081,\n",
       " 0.019378626719117165,\n",
       " 0.009478971362113953,\n",
       " 0.014276131987571716,\n",
       " -0.002074585296213627,\n",
       " 0.004831086378544569,\n",
       " 0.01439826563000679,\n",
       " 0.00026483615511097014,\n",
       " 0.025254638865590096,\n",
       " -0.009146494790911674,\n",
       " -0.023409055545926094,\n",
       " -0.02749376744031906,\n",
       " 0.015809593722224236,\n",
       " 0.010076072067022324,\n",
       " 0.01871367357671261,\n",
       " -0.029556477442383766,\n",
       " 0.048582274466753006,\n",
       " 0.018876520916819572,\n",
       " 0.0370473749935627,\n",
       " 0.006296697072684765,\n",
       " -0.0072737704031169415,\n",
       " 0.014276131987571716,\n",
       " 0.008739381097257137,\n",
       " -0.001730234595015645,\n",
       " -0.0023680466692894697,\n",
       " -0.019894305616617203,\n",
       " 0.008189776912331581,\n",
       " 0.008305125869810581,\n",
       " 0.00888865627348423,\n",
       " -0.0027734641917049885,\n",
       " -0.005886190105229616,\n",
       " 0.013394051231443882,\n",
       " -0.006422223523259163,\n",
       " -0.05458042025566101,\n",
       " -0.0034655581694096327,\n",
       " 0.0008333115256391466,\n",
       " 0.006924331188201904,\n",
       " 0.017940158024430275,\n",
       " -0.0035995664075016975,\n",
       " 0.01521249394863844,\n",
       " -0.04421258345246315,\n",
       " -0.01931077428162098,\n",
       " 0.0010372926481068134,\n",
       " 0.017723029479384422,\n",
       " 0.004831086378544569,\n",
       " 0.028742250055074692,\n",
       " 0.005462113302201033,\n",
       " -0.002339209197089076,\n",
       " 0.012172709219157696,\n",
       " -0.013319414108991623,\n",
       " -0.0032687862403690815,\n",
       " -0.029990732669830322,\n",
       " -0.017560184001922607,\n",
       " -0.03726450353860855,\n",
       " 0.008691884577274323,\n",
       " 0.032569121569395065,\n",
       " 0.027792317792773247,\n",
       " 0.011154924519360065,\n",
       " 0.0012654460733756423,\n",
       " -0.016827380284667015,\n",
       " 0.00715163629502058,\n",
       " -0.0004906572285108268,\n",
       " -0.03175489231944084,\n",
       " -0.0171259306371212,\n",
       " -0.028959376737475395,\n",
       " 0.008997219614684582,\n",
       " -0.017709460109472275,\n",
       " 0.0032128081656992435,\n",
       " -0.024006156250834465,\n",
       " 0.005265341140329838,\n",
       " 0.006734344642609358,\n",
       " 0.01462896354496479,\n",
       " -0.026218142360448837,\n",
       " -0.00386079796589911,\n",
       " 0.005088925361633301,\n",
       " 0.016325272619724274,\n",
       " 0.039788611233234406,\n",
       " 0.014981796033680439,\n",
       " -0.00014461029786616564,\n",
       " 0.020219996571540833,\n",
       " -0.015958869829773903,\n",
       " -0.004586818162351847,\n",
       " 0.00537051260471344,\n",
       " 0.0001160911051556468,\n",
       " -0.034007590264081955,\n",
       " 0.01380116492509842,\n",
       " -0.014710386283695698,\n",
       " 0.016447406262159348,\n",
       " 0.013774024322628975,\n",
       " 0.002586870454251766,\n",
       " -0.016135286539793015,\n",
       " 0.03712879866361618,\n",
       " 0.014995366334915161,\n",
       " 0.02977360598742962,\n",
       " 0.007911582477390766,\n",
       " 0.037753041833639145,\n",
       " 0.004342549480497837,\n",
       " 0.006262770853936672,\n",
       " 0.017193781211972237,\n",
       " -0.0008964990265667439,\n",
       " 0.0077758776023983955,\n",
       " 0.010469615459442139,\n",
       " 0.000706936523783952,\n",
       " 0.042801253497600555,\n",
       " 0.003401098307222128,\n",
       " 0.0056860256008803844,\n",
       " -0.0003543164348229766,\n",
       " -0.0015317664947360754,\n",
       " -0.029827887192368507,\n",
       " -0.014316842891275883,\n",
       " 0.01994858682155609,\n",
       " 0.010225347243249416,\n",
       " 0.044511131942272186,\n",
       " -0.011270273476839066,\n",
       " -0.022214854136109352,\n",
       " -0.027697324752807617,\n",
       " -0.0012535719433799386,\n",
       " -0.03281338885426521,\n",
       " 0.013964011333882809,\n",
       " -0.0010449260007590055,\n",
       " -0.022336989641189575,\n",
       " 0.023531191051006317,\n",
       " 0.007300911471247673,\n",
       " 0.012098072096705437,\n",
       " -0.02292051911354065,\n",
       " 0.009404334239661694,\n",
       " -0.03726450353860855,\n",
       " -0.0020186069887131453,\n",
       " -0.0025325885508209467,\n",
       " 0.007972649298608303,\n",
       " 0.04190560430288315,\n",
       " -0.026191001757979393,\n",
       " 0.012756239622831345,\n",
       " -0.042991239577531815,\n",
       " -0.007165206596255302,\n",
       " -0.015551755204796791,\n",
       " -0.004213630221784115,\n",
       " 0.0008570598438382149,\n",
       " -0.02097994275391102,\n",
       " 0.02606886811554432,\n",
       " 0.05107923969626427,\n",
       " 0.0370202362537384,\n",
       " -0.0027293602470308542,\n",
       " 0.003185667097568512,\n",
       " 0.021658465266227722,\n",
       " -0.003353601787239313,\n",
       " 0.0029888954013586044,\n",
       " 0.02000286802649498,\n",
       " -0.0016903713112697005,\n",
       " 0.00852225348353386,\n",
       " -0.0044239722192287445,\n",
       " 0.0009736810461618006,\n",
       " -0.017492331564426422,\n",
       " 0.017058078199625015,\n",
       " 0.007809803821146488,\n",
       " 0.026652397587895393,\n",
       " -0.0008409448782913387,\n",
       " -0.0006916697602719069,\n",
       " -0.009071857668459415,\n",
       " -0.005373904947191477,\n",
       " -0.033871885389089584,\n",
       " -0.002403669059276581,\n",
       " 0.039924316108226776,\n",
       " -0.005641921889036894,\n",
       " 0.03463183343410492,\n",
       " -0.022608399391174316,\n",
       " 0.00490911677479744,\n",
       " 0.010320340283215046,\n",
       " 0.02115635946393013,\n",
       " 0.009431474842131138,\n",
       " -0.0022849275264889,\n",
       " 0.020287849009037018,\n",
       " 0.011792736127972603,\n",
       " -0.007674099411815405,\n",
       " 0.02814514935016632,\n",
       " 0.0044816466979682446,\n",
       " -0.023911163210868835,\n",
       " -0.028443699702620506,\n",
       " -0.0347132571041584,\n",
       " -0.026367418467998505,\n",
       " 0.01833370141685009,\n",
       " 0.006792019121348858,\n",
       " 0.01120242103934288,\n",
       " 0.023504048585891724,\n",
       " 0.01727520488202572,\n",
       " -0.022934090346097946,\n",
       " -0.004630921874195337,\n",
       " -0.02365332469344139,\n",
       " -0.014873231761157513,\n",
       " -0.014411835931241512,\n",
       " -0.020152144134044647,\n",
       " -0.030533552169799805,\n",
       " -0.031076369807124138,\n",
       " -0.010266058146953583,\n",
       " 0.0018845986342057586,\n",
       " 0.004233985673636198,\n",
       " 0.004172918852418661,\n",
       " -0.021088507026433945,\n",
       " 0.005506217014044523,\n",
       " -0.029176505282521248,\n",
       " -0.009207562543451786,\n",
       " 0.017492331564426422,\n",
       " -0.015063218772411346,\n",
       " 0.04000573605298996,\n",
       " -0.019690748304128647,\n",
       " 0.02334120310842991,\n",
       " 0.014927513897418976,\n",
       " 0.005295875016599894,\n",
       " -0.01095136720687151,\n",
       " -0.0085629653185606,\n",
       " 0.008691884577274323,\n",
       " -0.001731082797050476,\n",
       " 0.029692182317376137,\n",
       " 0.008176206611096859,\n",
       " -0.02323264069855213,\n",
       " -0.01680023781955242,\n",
       " 0.002574996091425419,\n",
       " -0.00010951791045954451,\n",
       " 0.012600178830325603,\n",
       " -0.02040998265147209,\n",
       " 0.026096008718013763,\n",
       " 0.005166955292224884,\n",
       " 0.003087281249463558,\n",
       " 0.002196719404309988,\n",
       " -0.010537467896938324,\n",
       " -0.020722104236483574,\n",
       " 0.03805159032344818,\n",
       " -0.022241996601223946,\n",
       " -0.008087998256087303,\n",
       " -0.020640680566430092,\n",
       " -0.03487610071897507,\n",
       " -0.01861868053674698,\n",
       " 0.011154924519360065,\n",
       " -0.013353340327739716,\n",
       " 0.031646329909563065,\n",
       " 0.01439826563000679,\n",
       " 0.004010072909295559,\n",
       " -0.0015631482237949967,\n",
       " -0.002369742840528488,\n",
       " -0.003467254340648651,\n",
       " 0.0043730828911066055,\n",
       " 0.00040372140938416123,\n",
       " 0.03281338885426521,\n",
       " -0.0020186069887131453,\n",
       " 0.021034223958849907,\n",
       " 0.022119861096143723,\n",
       " -0.009506111964583397,\n",
       " -0.013271916657686234,\n",
       " 0.0005674151470884681,\n",
       " 0.008182992227375507,\n",
       " 0.03721022233366966,\n",
       " -0.033817604184150696,\n",
       " -0.010903870686888695,\n",
       " 0.011304199695587158,\n",
       " -0.010408548638224602,\n",
       " 0.012613749131560326,\n",
       " -0.008366192691028118,\n",
       " -0.0030482662841677666,\n",
       " -0.016270989552140236,\n",
       " -0.01317013893276453,\n",
       " -0.008013361133635044,\n",
       " 0.02439969964325428,\n",
       " 0.011799521744251251,\n",
       " -0.01648811809718609,\n",
       " 0.006432401482015848,\n",
       " 0.008440830744802952,\n",
       " -0.009587535634636879,\n",
       " -0.013964011333882809,\n",
       " -0.012043789960443974,\n",
       " 0.004943042527884245,\n",
       " -0.024046868085861206,\n",
       " -0.030017873272299767,\n",
       " 0.01883580908179283,\n",
       " -0.005339978728443384,\n",
       " 0.0017607681220397353,\n",
       " -0.006961649749428034,\n",
       " -0.01737019792199135,\n",
       " 0.008162636309862137,\n",
       " 0.03476753830909729,\n",
       " -0.015158211812376976,\n",
       " 0.0178180243819952,\n",
       " 0.014900373294949532,\n",
       " 0.008841159753501415,\n",
       " -0.01680023781955242,\n",
       " 0.02171274833381176,\n",
       " -0.020993512123823166,\n",
       " -0.027534477412700653,\n",
       " 0.011304199695587158,\n",
       " -0.03712879866361618,\n",
       " -0.01198950782418251,\n",
       " -0.007076998706907034,\n",
       " 0.002427417319267988,\n",
       " -0.0005818337667733431,\n",
       " 0.006300089415162802,\n",
       " -0.015280346386134624,\n",
       " -0.012851232662796974,\n",
       " 0.01796729862689972,\n",
       " 0.019270064309239388,\n",
       " -0.006595246959477663,\n",
       " 0.014995366334915161,\n",
       " 0.005424794275313616,\n",
       " 0.008569750003516674,\n",
       " -0.011819876730442047,\n",
       " 0.018781526014208794,\n",
       " -0.0351746529340744,\n",
       " -0.0005233111442066729,\n",
       " 0.0029685397166758776,\n",
       " -0.013991151936352253,\n",
       " 5.523604340851307e-05,\n",
       " -0.016786668449640274,\n",
       " 0.012281272560358047,\n",
       " -0.01990787498652935,\n",
       " 0.008257629349827766,\n",
       " -0.005272126756608486,\n",
       " 0.012396621517837048,\n",
       " 0.005709774326533079,\n",
       " 0.004352727439254522,\n",
       " -0.0028023014310747385,\n",
       " 0.009784307330846786,\n",
       " 0.009248273447155952,\n",
       " -0.0016123411478474736,\n",
       " -0.006469720508903265,\n",
       " 0.001772642252035439,\n",
       " 0.014642533846199512,\n",
       " 0.005211059469729662,\n",
       " -0.029990732669830322,\n",
       " -0.028769390657544136,\n",
       " -0.005102495662868023,\n",
       " -0.01593172922730446,\n",
       " -0.03254197910428047,\n",
       " 0.0035622476134449244,\n",
       " -0.013183709233999252,\n",
       " 0.04809373617172241,\n",
       " 0.03042498789727688,\n",
       " 0.000775212945882231,\n",
       " -0.004057569894939661,\n",
       " -0.01120242103934288,\n",
       " -0.03004501387476921,\n",
       " -0.0086783142760396,\n",
       " 0.0003439265419729054,\n",
       " 0.021264921873807907,\n",
       " -0.0011085375444963574,\n",
       " 0.030940664932131767,\n",
       " -0.004630921874195337,\n",
       " 0.01574174128472805,\n",
       " -0.008576535619795322,\n",
       " 0.017112359404563904,\n",
       " 0.009743595495820045,\n",
       " 0.006724166683852673,\n",
       " -0.017804453149437904,\n",
       " 0.006571498699486256,\n",
       " -0.014710386283695698,\n",
       " -0.015131071209907532,\n",
       " -0.020192855969071388,\n",
       " -0.015171782113611698,\n",
       " 0.0337904654443264,\n",
       " -0.02411472052335739,\n",
       " -0.017193781211972237,\n",
       " 0.022947659716010094,\n",
       " 0.003185667097568512,\n",
       " -0.00703628733754158,\n",
       " -0.0038506200071424246,\n",
       " 0.011148138903081417,\n",
       " 0.0027598938904702663,\n",
       " -0.004172918852418661,\n",
       " 0.020057151094079018,\n",
       " -0.0173566285520792,\n",
       " -0.015334628522396088,\n",
       " 0.0013629838358610868,\n",
       " -0.01139240711927414,\n",
       " -0.010008219629526138,\n",
       " -0.0003201782237738371,\n",
       " 0.002374831819906831,\n",
       " 0.0010330518707633018,\n",
       " 0.010286414064466953,\n",
       " -0.007083783857524395,\n",
       " 0.0009821625426411629,\n",
       " -0.003294230904430151,\n",
       " -0.01544319186359644,\n",
       " 0.021359914913773537,\n",
       " 0.011480615474283695,\n",
       " 0.01838798262178898,\n",
       " 0.027792317792773247,\n",
       " 0.012362695299088955,\n",
       " 0.015036078169941902,\n",
       " -0.016515258699655533,\n",
       " -0.021129216998815536,\n",
       " -0.017614467069506645,\n",
       " 0.019147928804159164,\n",
       " 0.026679538190364838,\n",
       " -0.02610957995057106,\n",
       " -0.023205500096082687,\n",
       " 0.002807390410453081,\n",
       " 0.022567687556147575,\n",
       " -0.031049229204654694,\n",
       " -0.03202630206942558,\n",
       " 0.006713988725095987,\n",
       " 0.009858944453299046,\n",
       " -0.017058078199625015,\n",
       " -0.007762307301163673,\n",
       " -0.008596890605986118,\n",
       " -0.022377701476216316,\n",
       " 0.011467045173048973,\n",
       " -0.011928441002964973,\n",
       " 0.013699387200176716,\n",
       " -0.01578245311975479,\n",
       " -0.02036927081644535,\n",
       " 0.027670182287693024,\n",
       " -0.002303586807101965,\n",
       " -0.009913226589560509,\n",
       " 0.0012824091827496886,\n",
       " 0.0037013450637459755,\n",
       " -0.017763741314411163,\n",
       " -0.014832520857453346,\n",
       " 0.03172775357961655,\n",
       " -0.023164788261055946,\n",
       " -0.0064561497420072556,\n",
       " 0.19921445846557617,\n",
       " -0.02351761981844902,\n",
       " 0.008807233534753323,\n",
       " -0.006812374573200941,\n",
       " 0.010327125899493694,\n",
       " -0.007178777363151312,\n",
       " 0.013163353316485882,\n",
       " -0.006754700094461441,\n",
       " -0.0004018130712211132,\n",
       " 0.005075354594737291,\n",
       " -0.005204274319112301,\n",
       " 0.010055716149508953,\n",
       " -0.03579889237880707,\n",
       " -0.003429935546591878,\n",
       " 0.005679240450263023,\n",
       " -0.021427767351269722,\n",
       " -0.03653169795870781,\n",
       " -0.010333910584449768,\n",
       " 0.00033396072103641927,\n",
       " 0.011148138903081417,\n",
       " 0.02708665281534195,\n",
       " 0.010557823814451694,\n",
       " -0.004617351572960615,\n",
       " -0.03878439590334892,\n",
       " 0.029176505282521248,\n",
       " -0.0010084554087370634,\n",
       " -0.010727454908192158,\n",
       " 0.01931077428162098,\n",
       " 0.023666895925998688,\n",
       " 0.0035859961062669754,\n",
       " -0.01985359378159046,\n",
       " 0.011921655386686325,\n",
       " -0.00784373003989458,\n",
       " 0.009146494790911674,\n",
       " -0.03175489231944084,\n",
       " -0.004759841598570347,\n",
       " 0.04513537511229515,\n",
       " -0.0072127035818994045,\n",
       " -0.010795306414365768,\n",
       " -0.009227917529642582,\n",
       " 0.011962367221713066,\n",
       " 0.004101673606783152,\n",
       " -0.020287849009037018,\n",
       " 0.000256354600423947,\n",
       " 0.0018642429495230317,\n",
       " 0.009431474842131138,\n",
       " ...]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embeddings for the first chunk\n",
    "create_embeddings(flattened_df['chunks'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.007107354234904051,\n",
       " -0.01739795319736004,\n",
       " -0.009769510477781296,\n",
       " -0.03062720224261284,\n",
       " -0.012626631185412407,\n",
       " 0.0031548854894936085,\n",
       " -0.0050478167831897736,\n",
       " -0.04123328998684883,\n",
       " -0.014590458944439888,\n",
       " -0.021311428397893906,\n",
       " 0.019170360639691353,\n",
       " 0.05081846937537193,\n",
       " -0.001183082116767764,\n",
       " 0.002591259777545929,\n",
       " -0.0383690781891346,\n",
       " -0.006128985434770584,\n",
       " 0.03544815257191658,\n",
       " -0.004604714922606945,\n",
       " 0.002406929386779666,\n",
       " -0.013463207520544529,\n",
       " -0.018957670778036118,\n",
       " 0.00901092030107975,\n",
       " 0.01583823375403881,\n",
       " -0.008734424598515034,\n",
       " -0.014562101103365421,\n",
       " 0.007082540541887283,\n",
       " 0.013122905977070332,\n",
       " -0.013243429362773895,\n",
       " 0.0029439690988510847,\n",
       " 0.00485285185277462,\n",
       " 0.00407653721049428,\n",
       " -0.01673152670264244,\n",
       " -0.015753159299492836,\n",
       " -0.04304823651909828,\n",
       " -0.027110746130347252,\n",
       " -0.004317584913223982,\n",
       " 0.008011282421648502,\n",
       " -0.009854585863649845,\n",
       " 0.02206292934715748,\n",
       " -0.009060547687113285,\n",
       " 0.004930838011205196,\n",
       " 0.00023971812333911657,\n",
       " -0.012080729939043522,\n",
       " 0.013158353976905346,\n",
       " -0.003718511201441288,\n",
       " 0.00689466530457139,\n",
       " -0.022176364436745644,\n",
       " -0.004434563685208559,\n",
       " 0.0014010882005095482,\n",
       " 0.013881496153771877,\n",
       " 0.0025026395451277494,\n",
       " 0.008060909807682037,\n",
       " -0.011237064376473427,\n",
       " 0.010301233269274235,\n",
       " -0.005079720169305801,\n",
       " 0.00290674832649529,\n",
       " 0.008025461807847023,\n",
       " -0.012718796730041504,\n",
       " 0.01309454720467329,\n",
       " 0.0022208266891539097,\n",
       " 0.01590912975370884,\n",
       " 0.004147433675825596,\n",
       " -0.0018805244471877813,\n",
       " 0.022672638297080994,\n",
       " 0.011116540059447289,\n",
       " -0.003431380959227681,\n",
       " -0.007359036244452,\n",
       " 0.0003863848396576941,\n",
       " -0.00407653721049428,\n",
       " 0.005090354476124048,\n",
       " 0.03244214877486229,\n",
       " 0.02797568216919899,\n",
       " 0.02360846847295761,\n",
       " -0.00571424188092351,\n",
       " -0.009542642161250114,\n",
       " -0.007064816541969776,\n",
       " -0.008606811054050922,\n",
       " 0.011385946534574032,\n",
       " -0.0005330515559762716,\n",
       " -0.005384574178606272,\n",
       " 0.035958606749773026,\n",
       " -0.03261229768395424,\n",
       " -0.01630614884197712,\n",
       " 0.005650435574352741,\n",
       " 0.019850965589284897,\n",
       " 0.006366488058120012,\n",
       " -0.009287416003644466,\n",
       " 0.009535552933812141,\n",
       " -0.010194888338446617,\n",
       " 0.010577728040516376,\n",
       " 0.021084560081362724,\n",
       " 0.026415962725877762,\n",
       " -0.012265060096979141,\n",
       " 0.03760340064764023,\n",
       " -0.010301233269274235,\n",
       " 0.019496483728289604,\n",
       " -0.01693003810942173,\n",
       " 0.025012215599417686,\n",
       " -0.00679541053250432,\n",
       " -0.05989319831132889,\n",
       " 0.005809952039271593,\n",
       " 0.00515770586207509,\n",
       " -0.0429915189743042,\n",
       " -0.007578814867883921,\n",
       " -0.003750414354726672,\n",
       " -0.009032188914716244,\n",
       " 0.01851811446249485,\n",
       " 0.001020906725898385,\n",
       " 0.01752556674182415,\n",
       " -0.00261252885684371,\n",
       " -0.007444111630320549,\n",
       " 0.05736928805708885,\n",
       " 0.011860951781272888,\n",
       " -0.01824870891869068,\n",
       " 0.006012006662786007,\n",
       " -0.005200244020670652,\n",
       " -0.004824493546038866,\n",
       " -0.024359969422221184,\n",
       " -0.006012006662786007,\n",
       " -0.01603674329817295,\n",
       " 0.011102360673248768,\n",
       " 0.009372491389513016,\n",
       " 0.0390213243663311,\n",
       " 0.007359036244452,\n",
       " 0.018900955095887184,\n",
       " 0.019056925550103188,\n",
       " -0.007834041491150856,\n",
       " 0.013661717996001244,\n",
       " -0.01349156629294157,\n",
       " 0.0171994436532259,\n",
       " 0.029209276661276817,\n",
       " 0.0006894665420986712,\n",
       " 0.013874406926333904,\n",
       " 0.009712793864309788,\n",
       " 0.0009110174723900855,\n",
       " 0.02757866121828556,\n",
       " -0.04146015644073486,\n",
       " -0.0027188733220100403,\n",
       " -0.004757142160087824,\n",
       " -0.06295591592788696,\n",
       " -0.0024140190798789263,\n",
       " 0.019368870183825493,\n",
       " -0.01958155818283558,\n",
       " 0.01573897898197174,\n",
       " -0.010598997585475445,\n",
       " 0.02377861924469471,\n",
       " 0.024756988510489464,\n",
       " 0.00368660781532526,\n",
       " 0.012038192711770535,\n",
       " 0.002243868075311184,\n",
       " 0.005196698941290379,\n",
       " -0.009039279073476791,\n",
       " 0.027167463675141335,\n",
       " -0.017638999968767166,\n",
       " -0.00736612593755126,\n",
       " 0.030201824381947517,\n",
       " 0.0034508774988353252,\n",
       " 0.01494494080543518,\n",
       " -0.0021003030706197023,\n",
       " -0.020148729905486107,\n",
       " -0.00019363552564755082,\n",
       " -0.004813858773559332,\n",
       " 0.016958395019173622,\n",
       " -0.014186350628733635,\n",
       " 0.005742600653320551,\n",
       " 0.02705402858555317,\n",
       " 0.0208293329924345,\n",
       " 0.004416839685291052,\n",
       " -0.013902764767408371,\n",
       " 0.004842217545956373,\n",
       " -0.019624097272753716,\n",
       " 0.02298458106815815,\n",
       " -0.0068521276116371155,\n",
       " 0.00727396085858345,\n",
       " -0.0038780278991907835,\n",
       " 0.00919525045901537,\n",
       " -0.000977482763119042,\n",
       " -0.005143526941537857,\n",
       " -0.013264697976410389,\n",
       " -0.026997312903404236,\n",
       " -0.013406490907073021,\n",
       " 0.011137809604406357,\n",
       " 0.015597186982631683,\n",
       " 0.03264065831899643,\n",
       " 0.0009234243771061301,\n",
       " 0.004980465397238731,\n",
       " 0.023934591561555862,\n",
       " -0.008096357807517052,\n",
       " -0.009117264300584793,\n",
       " -0.004565721843391657,\n",
       " 0.005600807722657919,\n",
       " 0.02675626426935196,\n",
       " 0.020673362538218498,\n",
       " -0.023197270929813385,\n",
       " -0.6570101976394653,\n",
       " -0.024033846333622932,\n",
       " -0.009457566775381565,\n",
       " -0.01288185827434063,\n",
       " 0.012548645958304405,\n",
       " 0.024189818650484085,\n",
       " 0.0021322062239050865,\n",
       " 0.0025398600846529007,\n",
       " 0.006352308671921492,\n",
       " -0.014462845399975777,\n",
       " -0.016745707020163536,\n",
       " 0.009053457528352737,\n",
       " 0.0034402431920170784,\n",
       " -0.010372129268944263,\n",
       " -0.010996016673743725,\n",
       " -0.003268319647759199,\n",
       " -0.004267957527190447,\n",
       " -0.0188442375510931,\n",
       " -0.018036019057035446,\n",
       " 0.023225629702210426,\n",
       " -0.0020506756845861673,\n",
       " 0.0052179680205881596,\n",
       " 0.0018805244471877813,\n",
       " -0.012974023818969727,\n",
       " 0.004668521694839001,\n",
       " -0.00971988309174776,\n",
       " 0.006777686532586813,\n",
       " -0.03298095986247063,\n",
       " 0.025125650689005852,\n",
       " 0.01532778050750494,\n",
       " -0.01238558441400528,\n",
       " 0.030598845332860947,\n",
       " -0.005420022178441286,\n",
       " -0.01357664167881012,\n",
       " 0.04664976894855499,\n",
       " 0.02285696752369404,\n",
       " 0.00010723065497586504,\n",
       " 0.027124926447868347,\n",
       " 0.01514345034956932,\n",
       " 0.0406661182641983,\n",
       " -0.018305424600839615,\n",
       " -0.020092012360692024,\n",
       " 0.016788244247436523,\n",
       " 0.0026178460102528334,\n",
       " -0.025380875915288925,\n",
       " -0.012236702255904675,\n",
       " -0.0008011282188817859,\n",
       " -0.0004820948524866253,\n",
       " 0.01093220990151167,\n",
       " -0.005558270029723644,\n",
       " 0.016348687931895256,\n",
       " -0.007295229472219944,\n",
       " 0.0019124278333038092,\n",
       " -0.007330677937716246,\n",
       " 0.008507556281983852,\n",
       " 0.00444874307140708,\n",
       " 0.024728629738092422,\n",
       " -0.02380697801709175,\n",
       " 0.0030060033313930035,\n",
       " 0.013129995204508305,\n",
       " -0.0034437880385667086,\n",
       " 0.00533140217885375,\n",
       " -0.008223971351981163,\n",
       " -0.02013454958796501,\n",
       " -0.01623525284230709,\n",
       " 0.007149892393499613,\n",
       " -0.015356139279901981,\n",
       " -0.0037610488943755627,\n",
       " 0.023821158334612846,\n",
       " 0.01105982344597578,\n",
       " 0.005781593732535839,\n",
       " 0.005834765732288361,\n",
       " -0.03468247130513191,\n",
       " 0.0038886622060090303,\n",
       " 0.0037575040478259325,\n",
       " 0.02216218411922455,\n",
       " 0.008833679370582104,\n",
       " -0.012754244729876518,\n",
       " -0.0011529511539265513,\n",
       " -0.011924758553504944,\n",
       " -0.007543366868048906,\n",
       " 0.004200606141239405,\n",
       " -0.026146557182073593,\n",
       " -0.00816725380718708,\n",
       " 0.01583823375403881,\n",
       " -0.011811324395239353,\n",
       " -0.02119799517095089,\n",
       " -0.0014046330470591784,\n",
       " 0.01425015740096569,\n",
       " 0.011364676989614964,\n",
       " 0.007114443928003311,\n",
       " 0.02440250664949417,\n",
       " -0.017284518107771873,\n",
       " 0.014306874014437199,\n",
       " -0.009188161231577396,\n",
       " 0.009443387389183044,\n",
       " -0.0062353298999369144,\n",
       " 0.003697242122143507,\n",
       " 0.010521011427044868,\n",
       " -0.03817056864500046,\n",
       " -0.007947475649416447,\n",
       " -0.005001734010875225,\n",
       " 0.006593356374651194,\n",
       " -0.006763507146388292,\n",
       " 0.022148005664348602,\n",
       " 0.02367936447262764,\n",
       " -0.014859865419566631,\n",
       " 0.018773341551423073,\n",
       " 0.03649741783738136,\n",
       " -0.02146740071475506,\n",
       " 0.0053881192579865456,\n",
       " -0.004739417694509029,\n",
       " -0.010081454180181026,\n",
       " 0.00019175234774593264,\n",
       " 0.013760972768068314,\n",
       " -0.03150631859898567,\n",
       " 0.012236702255904675,\n",
       " 0.00474650738760829,\n",
       " 0.01864572800695896,\n",
       " -0.02295622229576111,\n",
       " -0.010287053883075714,\n",
       " 0.020786795765161514,\n",
       " 0.013215070590376854,\n",
       " -0.008479197509586811,\n",
       " 0.003906386438757181,\n",
       " 0.0031017132569104433,\n",
       " -0.016844961792230606,\n",
       " 0.0012043509632349014,\n",
       " -0.006047454662621021,\n",
       " -0.0021658821497112513,\n",
       " 0.008238150738179684,\n",
       " -0.02023380436003208,\n",
       " 0.014484114944934845,\n",
       " -0.01613599807024002,\n",
       " 0.0031814714893698692,\n",
       " 0.0021517027635127306,\n",
       " 0.02509729191660881,\n",
       " 0.016150178387761116,\n",
       " 0.01841885969042778,\n",
       " -0.004335308913141489,\n",
       " -0.025508489459753036,\n",
       " -0.00032523678964935243,\n",
       " 0.010676982812583447,\n",
       " 0.006487011909484863,\n",
       " 0.018305424600839615,\n",
       " 0.0028659829404205084,\n",
       " -0.006671342067420483,\n",
       " -0.024459224194288254,\n",
       " 0.0025540392380207777,\n",
       " 0.009549732320010662,\n",
       " -0.014888223260641098,\n",
       " -0.010818775743246078,\n",
       " 0.027564482763409615,\n",
       " 0.016547197476029396,\n",
       " 0.03459739685058594,\n",
       " -0.022374873980879784,\n",
       " -0.010067274793982506,\n",
       " -0.015483752824366093,\n",
       " -0.019198719412088394,\n",
       " -0.008018371649086475,\n",
       " 0.005739055573940277,\n",
       " 0.03417201712727547,\n",
       " -0.004246688447892666,\n",
       " -0.01359082106500864,\n",
       " -0.017043471336364746,\n",
       " -0.023296525701880455,\n",
       " 0.009500104933977127,\n",
       " 0.0330660343170166,\n",
       " -0.025338338688015938,\n",
       " -0.03337797895073891,\n",
       " -0.004533818457275629,\n",
       " -0.02152411825954914,\n",
       " -0.005671704187989235,\n",
       " 0.022034570574760437,\n",
       " 0.008004192262887955,\n",
       " 0.0043601226061582565,\n",
       " 0.00872733537107706,\n",
       " -0.027918964624404907,\n",
       " 0.008337405510246754,\n",
       " 0.0035040497314184904,\n",
       " 0.029379427433013916,\n",
       " -0.004711059387773275,\n",
       " -0.011605724692344666,\n",
       " -0.006479922216385603,\n",
       " 0.000929627800360322,\n",
       " 0.016419583931565285,\n",
       " 0.03422873467206955,\n",
       " 0.01841885969042778,\n",
       " -0.018503936007618904,\n",
       " 0.016320329159498215,\n",
       " -0.017355414107441902,\n",
       " 0.006022640969604254,\n",
       " -0.000833474681712687,\n",
       " 0.01113071944564581,\n",
       " 0.0009136761073023081,\n",
       " -0.011017285287380219,\n",
       " 0.005590173415839672,\n",
       " 0.02221890166401863,\n",
       " 0.01765318028628826,\n",
       " 0.02182188257575035,\n",
       " -0.000665095925796777,\n",
       " 0.013200891204178333,\n",
       " 0.010428845882415771,\n",
       " -0.0024370604660362005,\n",
       " 0.01958155818283558,\n",
       " -0.03601532056927681,\n",
       " -0.013902764767408371,\n",
       " -0.008124716579914093,\n",
       " 0.03740489110350609,\n",
       " 0.026118198409676552,\n",
       " -0.0001416818267898634,\n",
       " -0.008216881193220615,\n",
       " -0.016277791932225227,\n",
       " -0.012669169344007969,\n",
       " 0.007408663630485535,\n",
       " 0.02847195602953434,\n",
       " -0.010421756654977798,\n",
       " -0.0023059023078531027,\n",
       " -0.00912435445934534,\n",
       " 0.0002753878361545503,\n",
       " -0.007515008095651865,\n",
       " -0.0032878159545361996,\n",
       " -0.005941110197454691,\n",
       " 0.020120371133089066,\n",
       " 0.00629204697906971,\n",
       " 0.011634083464741707,\n",
       " 0.020815154537558556,\n",
       " 0.036043681204319,\n",
       " 0.004023365210741758,\n",
       " -0.026515217497944832,\n",
       " -0.024714451283216476,\n",
       " 0.000370211637346074,\n",
       " 0.009556821547448635,\n",
       " 0.01093220990151167,\n",
       " 0.004569266922771931,\n",
       " -0.0014870499726384878,\n",
       " 0.02757866121828556,\n",
       " -0.020177088677883148,\n",
       " 0.03366156294941902,\n",
       " 0.01308036781847477,\n",
       " 0.0001375831343466416,\n",
       " 0.025182366371154785,\n",
       " 0.014165081083774567,\n",
       " -0.02450176328420639,\n",
       " 0.011761697009205818,\n",
       " -0.003360484726727009,\n",
       " 0.023622648790478706,\n",
       " 0.015455394051969051,\n",
       " -0.0036617941223084927,\n",
       " 0.01524270512163639,\n",
       " -0.013456118293106556,\n",
       " 0.004930838011205196,\n",
       " -0.0181919913738966,\n",
       " 0.01878752000629902,\n",
       " 0.0045586321502923965,\n",
       " -0.01590912975370884,\n",
       " 0.016816603019833565,\n",
       " 0.006515370216220617,\n",
       " 0.027139104902744293,\n",
       " 0.0314212404191494,\n",
       " 0.022700997069478035,\n",
       " -0.0006238874630071223,\n",
       " 0.004253778140991926,\n",
       " 0.0003877141571138054,\n",
       " 0.01035086065530777,\n",
       " 0.01834796369075775,\n",
       " 0.019624097272753716,\n",
       " -0.01630614884197712,\n",
       " 0.0157106202095747,\n",
       " 0.005937565583735704,\n",
       " -0.012818051502108574,\n",
       " -0.009400850161910057,\n",
       " 0.010776238515973091,\n",
       " -0.017667358741164207,\n",
       " 0.01327887736260891,\n",
       " 0.012201253324747086,\n",
       " -0.0009189933189190924,\n",
       " -0.005653980188071728,\n",
       " 0.02315473183989525,\n",
       " -0.0035359531175345182,\n",
       " -0.018078558146953583,\n",
       " -0.05113041400909424,\n",
       " 0.02757866121828556,\n",
       " -0.004774866160005331,\n",
       " -0.00882659014314413,\n",
       " -0.0018840692937374115,\n",
       " -0.041290007531642914,\n",
       " -0.01700093410909176,\n",
       " -0.0020506756845861673,\n",
       " 0.011690800078213215,\n",
       " 0.0003221350780222565,\n",
       " 0.0133923115208745,\n",
       " 0.02226143889129162,\n",
       " 0.019127823412418365,\n",
       " 0.013668807223439217,\n",
       " -0.002188923303037882,\n",
       " 0.03023018315434456,\n",
       " -0.013222160749137402,\n",
       " 0.008883306756615639,\n",
       " 0.010988927446305752,\n",
       " 0.0016217529773712158,\n",
       " -0.027124926447868347,\n",
       " -0.009400850161910057,\n",
       " -0.026571935042738914,\n",
       " 0.009663166478276253,\n",
       " -0.01603674329817295,\n",
       " -0.016291970387101173,\n",
       " -0.023920413106679916,\n",
       " -0.004565721843391657,\n",
       " 0.0033658018801361322,\n",
       " -0.020049475133419037,\n",
       " 0.017256159335374832,\n",
       " -0.02308383584022522,\n",
       " -0.010301233269274235,\n",
       " -0.014065826311707497,\n",
       " -0.008160164579749107,\n",
       " -0.03388843312859535,\n",
       " -0.001972689526155591,\n",
       " 0.04923039302229881,\n",
       " -0.0011511787306517363,\n",
       " -0.011896399781107903,\n",
       " -0.012307598255574703,\n",
       " -0.03462575376033783,\n",
       " -0.017440490424633026,\n",
       " 0.07066943496465683,\n",
       " 0.008195612579584122,\n",
       " -0.009081816300749779,\n",
       " 0.0106628043577075,\n",
       " 0.0019230622565373778,\n",
       " -0.0191845390945673,\n",
       " -0.02946450375020504,\n",
       " 0.0006806044839322567,\n",
       " 0.026898058131337166,\n",
       " 0.01248483918607235,\n",
       " -0.00969152431935072,\n",
       " 0.006050999276340008,\n",
       " 0.009358312003314495,\n",
       " -0.003534180810675025,\n",
       " -0.0021641096100211143,\n",
       " 0.017511386424303055,\n",
       " -0.01938304863870144,\n",
       " 0.0015171809354797006,\n",
       " 0.010698252357542515,\n",
       " -0.013456118293106556,\n",
       " 0.00233071600086987,\n",
       " 0.001822034944780171,\n",
       " 0.017185263335704803,\n",
       " 0.003094623563811183,\n",
       " -0.004516094457358122,\n",
       " -0.005997827276587486,\n",
       " 0.005246326327323914,\n",
       " 0.03386007621884346,\n",
       " 0.018163632601499557,\n",
       " -0.029407786205410957,\n",
       " 0.00531722279265523,\n",
       " 0.018007660284638405,\n",
       " -0.015795696526765823,\n",
       " -0.0035058222711086273,\n",
       " 0.011917668394744396,\n",
       " 0.008982561528682709,\n",
       " -0.004686245694756508,\n",
       " 0.008649349212646484,\n",
       " 0.024615196511149406,\n",
       " -0.018206169828772545,\n",
       " 0.02092858962714672,\n",
       " 0.02335324138402939,\n",
       " -0.01610763929784298,\n",
       " -0.0191845390945673,\n",
       " 0.009840406477451324,\n",
       " -0.007188885007053614,\n",
       " 0.0011511787306517363,\n",
       " 0.02159501425921917,\n",
       " 0.011761697009205818,\n",
       " -0.00466143200173974,\n",
       " 0.03842579573392868,\n",
       " 0.029407786205410957,\n",
       " -0.007826952263712883,\n",
       " 0.005044272169470787,\n",
       " -0.01640540547668934,\n",
       " -0.010038916952908039,\n",
       " 0.014129633083939552,\n",
       " -0.0095071941614151,\n",
       " -0.0022314612288028,\n",
       " -0.01613599807024002,\n",
       " -0.00806799903512001,\n",
       " -0.012413942255079746,\n",
       " 0.012101998552680016,\n",
       " 0.0023165366146713495,\n",
       " -0.013661717996001244,\n",
       " -0.022942043840885162,\n",
       " 0.0013620952377095819,\n",
       " -0.021977854892611504,\n",
       " -0.031137656420469284,\n",
       " -0.013434849679470062,\n",
       " -0.013831868767738342,\n",
       " -0.01650466024875641,\n",
       " -0.018603190779685974,\n",
       " 0.007798593491315842,\n",
       " 0.006671342067420483,\n",
       " 0.02328234538435936,\n",
       " 0.022048750892281532,\n",
       " -0.023395780473947525,\n",
       " -0.0006455994443967938,\n",
       " 0.0214957594871521,\n",
       " -0.01531360112130642,\n",
       " -0.026203272864222527,\n",
       " 0.004643708001822233,\n",
       " -0.04222583770751953,\n",
       " -0.021836061030626297,\n",
       " 0.006639438681304455,\n",
       " -0.006781231611967087,\n",
       " -0.014399039559066296,\n",
       " -0.004909568931907415,\n",
       " -0.00034429016523063183,\n",
       " 0.01968081295490265,\n",
       " 0.0008219539886340499,\n",
       " 0.03476754575967789,\n",
       " -0.017483027651906013,\n",
       " -0.003697242122143507,\n",
       " 0.013711345382034779,\n",
       " 0.014441576786339283,\n",
       " -0.00922360923141241,\n",
       " 0.0035714013502001762,\n",
       " -0.03366156294941902,\n",
       " 0.014087095856666565,\n",
       " -0.024331610649824142,\n",
       " -0.01327887736260891,\n",
       " 0.0020010480657219887,\n",
       " 0.010492652654647827,\n",
       " 0.00015530720702372491,\n",
       " 0.0200069360435009,\n",
       " 0.03462575376033783,\n",
       " 0.002123344223946333,\n",
       " -0.01755392551422119,\n",
       " 0.00969152431935072,\n",
       " -0.022644279524683952,\n",
       " -0.009656076319515705,\n",
       " -0.010301233269274235,\n",
       " 0.015980027616024017,\n",
       " 0.015072554349899292,\n",
       " -0.02255920320749283,\n",
       " 0.024884602054953575,\n",
       " 0.02447340451180935,\n",
       " -0.007387395016849041,\n",
       " -0.026912236586213112,\n",
       " -0.019850965589284897,\n",
       " 0.01904274709522724,\n",
       " 0.03082571178674698,\n",
       " -0.011577365919947624,\n",
       " 0.002481370698660612,\n",
       " 0.0013682986609637737,\n",
       " 0.008046730421483517,\n",
       " -0.0063062263652682304,\n",
       " 0.007493739016354084,\n",
       " 0.0043317642994225025,\n",
       " 0.011988565325737,\n",
       " -0.012073640711605549,\n",
       " -0.04599752277135849,\n",
       " -0.022899506613612175,\n",
       " -0.013271788135170937,\n",
       " -0.013158353976905346,\n",
       " 0.010357949882745743,\n",
       " -0.006745783146470785,\n",
       " -0.019694993272423744,\n",
       " -0.04520348459482193,\n",
       " 0.005852489732205868,\n",
       " 0.0014188123168423772,\n",
       " -0.020418135449290276,\n",
       " -0.018631547689437866,\n",
       " -0.042282555252313614,\n",
       " -0.03278245031833649,\n",
       " -0.004498370457440615,\n",
       " 0.00464725261554122,\n",
       " 0.029152559116482735,\n",
       " -0.009563911706209183,\n",
       " 0.010712431743741035,\n",
       " -0.009039279073476791,\n",
       " -0.016788244247436523,\n",
       " -0.01573897898197174,\n",
       " -0.023268166929483414,\n",
       " -0.01670316979289055,\n",
       " -0.0016642906703054905,\n",
       " 0.03383171558380127,\n",
       " 0.020673362538218498,\n",
       " -0.0019425586797297,\n",
       " 0.008954202756285667,\n",
       " 0.011421394534409046,\n",
       " -0.00747247040271759,\n",
       " -0.008620990440249443,\n",
       " 0.009159802459180355,\n",
       " 0.012194164097309113,\n",
       " 0.011293780989944935,\n",
       " -0.02728089690208435,\n",
       " 0.011598635464906693,\n",
       " 0.017284518107771873,\n",
       " -0.0038035865873098373,\n",
       " -0.0010669893817976117,\n",
       " -0.0016509976703673601,\n",
       " -0.02206292934715748,\n",
       " 0.020219625905156136,\n",
       " 0.0037256006617099047,\n",
       " -0.022998761385679245,\n",
       " 0.0031229821033775806,\n",
       " -0.007578814867883921,\n",
       " 0.014292694628238678,\n",
       " -0.0032594576478004456,\n",
       " 0.0157106202095747,\n",
       " 0.015001657418906689,\n",
       " 0.0008441091049462557,\n",
       " -0.0023253988474607468,\n",
       " 0.016589734703302383,\n",
       " 0.0028907968662679195,\n",
       " -0.008535915054380894,\n",
       " 0.0046295286156237125,\n",
       " 0.014498294331133366,\n",
       " -0.009953840635716915,\n",
       " 0.010457204654812813,\n",
       " -0.026004763320088387,\n",
       " 0.014264335855841637,\n",
       " -0.030542127788066864,\n",
       " -0.016221074387431145,\n",
       " -0.00252568069845438,\n",
       " 0.0015747841680422425,\n",
       " -0.013427759520709515,\n",
       " 0.011832593008875847,\n",
       " 0.039701931178569794,\n",
       " 0.003732690354809165,\n",
       " 0.008883306756615639,\n",
       " 0.00010324273898731917,\n",
       " -0.007164071314036846,\n",
       " -0.0002800404035951942,\n",
       " -0.01640540547668934,\n",
       " 0.003449105191975832,\n",
       " -0.016291970387101173,\n",
       " -0.009450477547943592,\n",
       " -0.00840121228247881,\n",
       " -0.058248404413461685,\n",
       " -0.026245811954140663,\n",
       " -0.006777686532586813,\n",
       " 0.0016190942842513323,\n",
       " -0.0015455393586307764,\n",
       " 0.007741876412183046,\n",
       " -0.011010196059942245,\n",
       " -0.008181433193385601,\n",
       " -0.012038192711770535,\n",
       " 0.002493777545168996,\n",
       " 0.026316707953810692,\n",
       " -0.026174915954470634,\n",
       " 0.029209276661276817,\n",
       " 0.026401782408356667,\n",
       " -0.018461396917700768,\n",
       " -0.00533140217885375,\n",
       " 0.007213698700070381,\n",
       " -0.01511509157717228,\n",
       " -0.04883337393403053,\n",
       " 0.008216881193220615,\n",
       " 0.0032559128012508154,\n",
       " -0.01289603766053915,\n",
       " 0.015597186982631683,\n",
       " -0.006738693453371525,\n",
       " 0.004980465397238731,\n",
       " -0.01481732726097107,\n",
       " -0.024615196511149406,\n",
       " 0.020857691764831543,\n",
       " 0.032130204141139984,\n",
       " -0.00949301477521658,\n",
       " -0.029010767117142677,\n",
       " 0.010620266199111938,\n",
       " -0.010889671742916107,\n",
       " 0.01812109537422657,\n",
       " -0.008734424598515034,\n",
       " -0.0023253988474607468,\n",
       " -0.03150631859898567,\n",
       " -0.006713879760354757,\n",
       " -0.01881587877869606,\n",
       " 0.016774065792560577,\n",
       " -0.01868826523423195,\n",
       " 0.01580987498164177,\n",
       " 0.0072207883931696415,\n",
       " -0.0034225189592689276,\n",
       " 0.022077109664678574,\n",
       " 0.013966571539640427,\n",
       " -0.013775152154266834,\n",
       " -0.012690437957644463,\n",
       " -0.03125109151005745,\n",
       " 0.02010619081556797,\n",
       " -0.01938304863870144,\n",
       " 0.03224363923072815,\n",
       " 0.018674086779356003,\n",
       " 0.004278591834008694,\n",
       " -0.01968081295490265,\n",
       " 0.0010891444981098175,\n",
       " -0.0178516898304224,\n",
       " 0.0320734865963459,\n",
       " -0.007359036244452,\n",
       " -0.010223247110843658,\n",
       " 0.012853499501943588,\n",
       " -0.022445769980549812,\n",
       " 0.015668082982301712,\n",
       " -0.020063653588294983,\n",
       " -0.020418135449290276,\n",
       " 0.0027738178614526987,\n",
       " -0.018830057233572006,\n",
       " -0.04018402472138405,\n",
       " 0.016490479931235313,\n",
       " 0.007614262867718935,\n",
       " -0.012158716097474098,\n",
       " 0.003651159582659602,\n",
       " -0.006635894067585468,\n",
       " -0.022077109664678574,\n",
       " -0.0040410892106592655,\n",
       " -0.007592994254082441,\n",
       " -0.021878598257899284,\n",
       " -0.005122257862240076,\n",
       " -0.013215070590376854,\n",
       " -0.003934744745492935,\n",
       " 0.010287053883075714,\n",
       " 0.0016953079029917717,\n",
       " 0.017440490424633026,\n",
       " -0.0005618532304652035,\n",
       " -0.001657201093621552,\n",
       " 0.03547650948166847,\n",
       " -0.012392673641443253,\n",
       " 0.024459224194288254,\n",
       " -0.03303767740726471,\n",
       " 0.014512473717331886,\n",
       " -0.021141277626156807,\n",
       " -0.004721693694591522,\n",
       " -0.0038603036664426327,\n",
       " 0.009578090161085129,\n",
       " 0.006713879760354757,\n",
       " -0.018773341551423073,\n",
       " -0.008422480896115303,\n",
       " -0.0008091040654107928,\n",
       " -0.0066536180675029755,\n",
       " 0.002376798540353775,\n",
       " -0.0021003030706197023,\n",
       " 0.0033622572664171457,\n",
       " 0.005785138346254826,\n",
       " 0.009627717547118664,\n",
       " 0.006345218978822231,\n",
       " -0.008982561528682709,\n",
       " -0.016065102070569992,\n",
       " 0.013796420767903328,\n",
       " -0.0102516058832407,\n",
       " 0.011088182218372822,\n",
       " 0.006075812969356775,\n",
       " -0.0018503934843465686,\n",
       " 0.009053457528352737,\n",
       " -0.019964398816227913,\n",
       " 0.026415962725877762,\n",
       " 0.012754244729876518,\n",
       " -0.015512111596763134,\n",
       " -0.013498656451702118,\n",
       " -0.019453946501016617,\n",
       " 0.009450477547943592,\n",
       " -0.0035058222711086273,\n",
       " -0.03502277284860611,\n",
       " -0.01484568603336811,\n",
       " -0.03448396176099777,\n",
       " -0.02119799517095089,\n",
       " 0.022332334890961647,\n",
       " -0.013285967521369457,\n",
       " -0.010606086812913418,\n",
       " 0.011761697009205818,\n",
       " 0.005987192969769239,\n",
       " -0.011449753306806087,\n",
       " 0.003360484726727009,\n",
       " -0.022573383525013924,\n",
       " -0.024813706055283546,\n",
       " -0.010712431743741035,\n",
       " 0.008769872598350048,\n",
       " -0.025650283321738243,\n",
       " -0.006079358048737049,\n",
       " -0.021339787170290947,\n",
       " 0.01782333105802536,\n",
       " 0.00901092030107975,\n",
       " -0.04018402472138405,\n",
       " -0.018659906461834908,\n",
       " 0.008904575370252132,\n",
       " -0.025621924549341202,\n",
       " -0.0045090047642588615,\n",
       " -0.0013425986981019378,\n",
       " 0.00949301477521658,\n",
       " 0.010457204654812813,\n",
       " -0.018433038145303726,\n",
       " 0.01349156629294157,\n",
       " 0.00023019143554847687,\n",
       " -0.003078671870753169,\n",
       " 0.019850965589284897,\n",
       " -0.01484568603336811,\n",
       " -0.013619179837405682,\n",
       " 0.018858416005969048,\n",
       " 0.003863848512992263,\n",
       " 0.024686092510819435,\n",
       " -0.016362866386771202,\n",
       " -0.019751710817217827,\n",
       " -0.024714451283216476,\n",
       " 0.013966571539640427,\n",
       " 0.01610763929784298,\n",
       " 0.0005268481327220798,\n",
       " 0.02616073563694954,\n",
       " 0.0007293457165360451,\n",
       " -0.014313963241875172,\n",
       " 0.000867150432895869,\n",
       " 0.008628079667687416,\n",
       " 0.024033846333622932,\n",
       " -0.0049272929318249226,\n",
       " 0.012101998552680016,\n",
       " 0.005749690346419811,\n",
       " -0.012924396432936192,\n",
       " 0.012577003799378872,\n",
       " -0.007919116877019405,\n",
       " 0.0033126298803836107,\n",
       " -0.007897848263382912,\n",
       " -0.01115907821804285,\n",
       " -0.01279678288847208,\n",
       " -0.002396295079961419,\n",
       " -0.013087457977235317,\n",
       " -0.001530473935417831,\n",
       " -0.0031176649499684572,\n",
       " -0.05498717352747917,\n",
       " -0.01824870891869068,\n",
       " 0.019666634500026703,\n",
       " 0.00017580068379174918,\n",
       " 0.023324884474277496,\n",
       " -0.011215794831514359,\n",
       " -0.013654627837240696,\n",
       " -0.015767337754368782,\n",
       " 0.019156180322170258,\n",
       " -0.016419583931565285,\n",
       " -0.022743534296751022,\n",
       " 0.026217453181743622,\n",
       " 0.015625545755028725,\n",
       " 0.019666634500026703,\n",
       " -0.008649349212646484,\n",
       " -0.012243791483342648,\n",
       " -0.030173467472195625,\n",
       " -0.008982561528682709,\n",
       " 0.00033985916525125504,\n",
       " -0.006338129285722971,\n",
       " 0.008259419351816177,\n",
       " 0.0037114215083420277,\n",
       " 0.009152712300419807,\n",
       " -0.029152559116482735,\n",
       " 0.002158792456611991,\n",
       " -0.0016687217867001891,\n",
       " -0.024927139282226562,\n",
       " 0.0067741419188678265,\n",
       " -0.012520287185907364,\n",
       " 0.0016545425169169903,\n",
       " -0.0033161744941025972,\n",
       " -0.006277867592871189,\n",
       " 0.019425587728619576,\n",
       " 0.002896114019677043,\n",
       " -0.0003030817024409771,\n",
       " -0.0026408873964101076,\n",
       " -0.0005778048653155565,\n",
       " 0.015753159299492836,\n",
       " 0.0043388535268604755,\n",
       " 0.18342290818691254,\n",
       " -0.003333898726850748,\n",
       " 0.0025487220846116543,\n",
       " 0.03224363923072815,\n",
       " 0.007748966105282307,\n",
       " -0.023495035246014595,\n",
       " 0.03167646750807762,\n",
       " 0.019893502816557884,\n",
       " 0.008075089193880558,\n",
       " 0.018475577235221863,\n",
       " -0.005203788634389639,\n",
       " 0.0021800613030791283,\n",
       " -0.0027507764752954245,\n",
       " 0.007904937490820885,\n",
       " 0.003280726494267583,\n",
       " 0.008748603984713554,\n",
       " -0.027890605852007866,\n",
       " -0.012073640711605549,\n",
       " -0.03178990259766579,\n",
       " -0.015980027616024017,\n",
       " 0.023126374930143356,\n",
       " 0.01308036781847477,\n",
       " -0.025579385459423065,\n",
       " -6.773920176783577e-05,\n",
       " 0.03947506099939346,\n",
       " 0.02023380436003208,\n",
       " -0.025551028549671173,\n",
       " -0.009585180319845676,\n",
       " 0.01238558441400528,\n",
       " 0.0035767185036092997,\n",
       " -0.019127823412418365,\n",
       " -0.00979077909141779,\n",
       " -0.008231060579419136,\n",
       " -0.0099183926358819,\n",
       " -0.004147433675825596,\n",
       " -0.011570276692509651,\n",
       " -0.015625545755028725,\n",
       " 0.022871147841215134,\n",
       " 0.0015331325121223927,\n",
       " 0.01814945414662361,\n",
       " -0.0357033796608448,\n",
       " 0.005661069881170988,\n",
       " -0.009216519072651863,\n",
       " -0.009776600636541843,\n",
       " -0.017156904563307762,\n",
       " 0.03366156294941902,\n",
       " ...]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = create_embeddings(\"cat\")\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "      <td>[-0.017071647569537163, 0.002827746095135808, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "      <td>[-0.01478797011077404, 0.0016882119234651327, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "      <td>[-0.03678734600543976, -0.020647864788770676, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "      <td>[-0.031713567674160004, -0.011103862896561623,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "      <td>[-0.008054508827626705, -0.033310648053884506,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  # Neural Network Frameworks As we have learned...   \n",
       "0  descent optimization While the `numpy` library...   \n",
       "0  should give us the opportunity to compute grad...   \n",
       "0  those computations on GPUs is very important. ...   \n",
       "0  API, there is also higher-level API, called Ke...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.017071647569537163, 0.002827746095135808, ...  \n",
       "0  [-0.01478797011077404, 0.0016882119234651327, ...  \n",
       "0  [-0.03678734600543976, -0.020647864788770676, ...  \n",
       "0  [-0.031713567674160004, -0.011103862896561623,...  \n",
       "0  [-0.008054508827626705, -0.033310648053884506,...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embeddings for the whole data chunks and store them in a list\n",
    "\n",
    "embeddings = []\n",
    "for chunk in flattened_df['chunks']:\n",
    "    embeddings.append(create_embeddings(chunk))\n",
    "\n",
    "# store the embeddings in the dataframe\n",
    "flattened_df['embeddings'] = embeddings\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Vector search and similiarity between our prompt and the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an search index and reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>indices</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "      <td>[-0.017071647569537163, 0.002827746095135808, ...</td>\n",
       "      <td>[0, 2, 11, 3, 1]</td>\n",
       "      <td>[0.0, 0.5233715652770051, 0.5282499261628433, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "      <td>[-0.01478797011077404, 0.0016882119234651327, ...</td>\n",
       "      <td>[1, 0, 32, 2, 50]</td>\n",
       "      <td>[0.0, 0.5701155822856672, 0.592189339823302, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "      <td>[-0.03678734600543976, -0.020647864788770676, ...</td>\n",
       "      <td>[2, 3, 0, 5, 1]</td>\n",
       "      <td>[0.0, 0.5057228769731683, 0.5233715652770051, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "      <td>[-0.031713567674160004, -0.011103862896561623,...</td>\n",
       "      <td>[3, 2, 0, 10, 11]</td>\n",
       "      <td>[0.0, 0.5057228769731683, 0.5461794498898873, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "      <td>[-0.008054508827626705, -0.033310648053884506,...</td>\n",
       "      <td>[4, 12, 10, 8, 9]</td>\n",
       "      <td>[0.0, 0.5201643386566065, 0.5530482770720577, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  # Neural Network Frameworks As we have learned...   \n",
       "0  descent optimization While the `numpy` library...   \n",
       "0  should give us the opportunity to compute grad...   \n",
       "0  those computations on GPUs is very important. ...   \n",
       "0  API, there is also higher-level API, called Ke...   \n",
       "\n",
       "                                          embeddings            indices  \\\n",
       "0  [-0.017071647569537163, 0.002827746095135808, ...   [0, 2, 11, 3, 1]   \n",
       "0  [-0.01478797011077404, 0.0016882119234651327, ...  [1, 0, 32, 2, 50]   \n",
       "0  [-0.03678734600543976, -0.020647864788770676, ...    [2, 3, 0, 5, 1]   \n",
       "0  [-0.031713567674160004, -0.011103862896561623,...  [3, 2, 0, 10, 11]   \n",
       "0  [-0.008054508827626705, -0.033310648053884506,...  [4, 12, 10, 8, 9]   \n",
       "\n",
       "                                           distances  \n",
       "0  [0.0, 0.5233715652770051, 0.5282499261628433, ...  \n",
       "0  [0.0, 0.5701155822856672, 0.592189339823302, 0...  \n",
       "0  [0.0, 0.5057228769731683, 0.5233715652770051, ...  \n",
       "0  [0.0, 0.5057228769731683, 0.5461794498898873, ...  \n",
       "0  [0.0, 0.5201643386566065, 0.5530482770720577, ...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "embeddings = flattened_df['embeddings'].to_list()\n",
    "\n",
    "# Create the search index\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)\n",
    "\n",
    "# To query the index, you can use the kneighbors method\n",
    "distances, indices = nbrs.kneighbors(embeddings)\n",
    "\n",
    "# Store the indices and distances in the DataFrame\n",
    "flattened_df['indices'] = indices.tolist()\n",
    "flattened_df['distances'] = distances.tolist()\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.\n",
      "data/perceptron.md\n",
      "[0.0, 0.5280529852680852, 0.5362877369675818, 0.5444286682491558, 0.5542846368687017]\n",
      "# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,\n",
      "data/perceptron.md\n",
      "[0.0, 0.45846243712732504, 0.5236378295599984, 0.5630992993431824, 0.5635853484842597]\n",
      "user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features\n",
      "data/perceptron.md\n",
      "[0.0, 0.5236378295599984, 0.5444286682491558, 0.5608301272935617, 0.5757997772113745]\n",
      "and to continue learning - go to Perceptron notebook. Here's an interesting article about perceptrons as well. ## Assignment In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve\n",
      "data/perceptron.md\n",
      "[0.0, 0.504632157497979, 0.5086118171906423, 0.5227902904235868, 0.5280529852680852]\n",
      "# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform\n",
      "data/own_framework.md\n",
      "[0.0, 0.45846243712732504, 0.5057848433822951, 0.5086118171906423, 0.5177924481045997]\n",
      "Index 25 not found in DataFrame\n",
      "in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.\n",
      "data/perceptron.md\n",
      "[0.0, 0.5280529852680852, 0.5362877369675818, 0.5444286682491558, 0.5542846368687017]\n",
      "# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,\n",
      "data/perceptron.md\n",
      "[0.0, 0.45846243712732504, 0.5236378295599984, 0.5630992993431824, 0.5635853484842597]\n",
      "user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features\n",
      "data/perceptron.md\n",
      "[0.0, 0.5236378295599984, 0.5444286682491558, 0.5608301272935617, 0.5757997772113745]\n",
      "and to continue learning - go to Perceptron notebook. Here's an interesting article about perceptrons as well. ## Assignment In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve\n",
      "data/perceptron.md\n",
      "[0.0, 0.504632157497979, 0.5086118171906423, 0.5227902904235868, 0.5280529852680852]\n",
      "# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform\n",
      "data/own_framework.md\n",
      "[0.0, 0.45846243712732504, 0.5057848433822951, 0.5086118171906423, 0.5177924481045997]\n",
      "Index 25 not found in DataFrame\n",
      "in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.\n",
      "data/perceptron.md\n",
      "[0.0, 0.5280529852680852, 0.5362877369675818, 0.5444286682491558, 0.5542846368687017]\n",
      "# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,\n",
      "data/perceptron.md\n",
      "[0.0, 0.45846243712732504, 0.5236378295599984, 0.5630992993431824, 0.5635853484842597]\n",
      "user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features\n",
      "data/perceptron.md\n",
      "[0.0, 0.5236378295599984, 0.5444286682491558, 0.5608301272935617, 0.5757997772113745]\n",
      "and to continue learning - go to Perceptron notebook. Here's an interesting article about perceptrons as well. ## Assignment In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve\n",
      "data/perceptron.md\n",
      "[0.0, 0.504632157497979, 0.5086118171906423, 0.5227902904235868, 0.5280529852680852]\n",
      "# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform\n",
      "data/own_framework.md\n",
      "[0.0, 0.45846243712732504, 0.5057848433822951, 0.5086118171906423, 0.5177924481045997]\n",
      "Index 25 not found in DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Your text question\n",
    "question = \"what is a perceptron?\"\n",
    "\n",
    "# Convert the question to a query vector\n",
    "query_vector = create_embeddings(question)  # You need to define this function\n",
    "\n",
    "# Find the most similar documents\n",
    "distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "index = []\n",
    "# Print the most similar documents\n",
    "for i in range(3):\n",
    "    index = indices[0][i]\n",
    "    for index in indices[0]:\n",
    "        print(flattened_df['chunks'].iloc[index])\n",
    "        print(flattened_df['path'].iloc[index])\n",
    "        print(flattened_df['distances'].iloc[index])\n",
    "    else:\n",
    "        print(f\"Index {index} not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together to answer a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://azure-openai-genai-test-001.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "print(openai.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='A perceptron is a type of artificial neuron, which is a fundamental building block of artificial neural networks. It is a mathematical model inspired by the biological neuron in the human brain. \\n\\nA perceptron takes multiple inputs, each multiplied by a corresponding weight, and sums them up. It then applies an activation function to the result to produce an output. The activation function is typically a simple threshold function that determines whether the perceptron should fire or not based on the weighted sum of inputs.\\n\\nPerceptrons are used to approximate functions or classify inputs into different categories based on the learned weights. They are often arranged in layers to form artificial neural networks, enabling more complex tasks like pattern recognition and decision-making.\\n\\nThe perceptron algorithm was first proposed by Frank Rosenblatt in 1957 and is considered one of the earliest forms of machine learning.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"what is a perceptron?\"\n",
    "\n",
    "def chatbot(user_input):\n",
    "    # Convert the question to a query vector\n",
    "    query_vector = create_embeddings(user_input)\n",
    "\n",
    "    # Find the most similar documents\n",
    "    distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "    # add documents to query  to provide context\n",
    "    history = []\n",
    "    for index in indices[0]:\n",
    "        history.append(flattened_df['chunks'].iloc[index])\n",
    "\n",
    "    # combine the history and the user input\n",
    "    history.append(user_input)\n",
    "\n",
    "    # create a message object\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assiatant that helps with AI questions.\"},\n",
    "        {\"role\": \"user\", \"content\": history[-1]}\n",
    "    ]\n",
    "\n",
    "    # use chat completion to generate a response\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"my-gpt-35-deploy\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message\n",
    "\n",
    "chatbot(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic example of how you can use Mean Average Precision (MAP) to evaluate the responses of your model based on their relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Define your test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"What is a perceptron?\",\n",
    "        \"relevant_responses\": [\"A perceptron is a type of artificial neuron.\", \"It's a binary classifier used in machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"A perceptron is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is machine learning?\",\n",
    "        \"relevant_responses\": [\"Machine learning is a method of data analysis that automates analytical model building.\", \"It's a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"],\n",
    "        \"irrelevant_responses\": [\"Machine learning is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is deep learning?\",\n",
    "        \"relevant_responses\": [\"Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled.\", \"It's a type of machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"Deep learning is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a neural network?\",\n",
    "        \"relevant_responses\": [\"A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates.\", \"It's a type of machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"A neural network is a type of fruit.\", \"It's a type of car.\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize the total average precision\n",
    "total_average_precision = 0\n",
    "\n",
    "# Test the RAG application\n",
    "for test_case in test_cases:\n",
    "    query = test_case[\"query\"]\n",
    "    relevant_responses = test_case[\"relevant_responses\"]\n",
    "    irrelevant_responses = test_case[\"irrelevant_responses\"]\n",
    "\n",
    "    # Generate a response using your RAG application\n",
    "    response = chatbot(query) \n",
    "\n",
    "    # Create a list of all responses and a list of true binary labels\n",
    "    all_responses = relevant_responses + irrelevant_responses\n",
    "    true_labels = [1] * len(relevant_responses) + [0] * len(irrelevant_responses)\n",
    "\n",
    "    # Create a list of predicted scores based on whether the response is the generated response\n",
    "    predicted_scores = [1 if resp == response else 0 for resp in all_responses]\n",
    "\n",
    "    # Calculate the average precision for this query\n",
    "    average_precision = average_precision_score(true_labels, predicted_scores)\n",
    "\n",
    "    # Add the average precision to the total average precision\n",
    "    total_average_precision += average_precision\n",
    "\n",
    "# Calculate the mean average precision\n",
    "mean_average_precision = total_average_precision / len(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
